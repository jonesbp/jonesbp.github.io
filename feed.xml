<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
<channel>
<title>La Tinaja</title>
<description>My name is Brian Jones. These are my notes on topics including books, publishing, tech, and history.</description>
<link>http://localhost:4000</link>
<atom:link href="http://tinaja.computer/feed.xml" rel="self" type="application/rss+xml" />

<item>
<title>Mapping Caps Lock to Escape in macOS Sierra</title>

<description>
    <![CDATA[
    <p>I use Vim and command mode in any GUI editors that support it, so I’m hitting the Esc key hundreds of times a day. I’ve always been curious about mapping my Caps Lock key to escape to cut down on the distance I have to reach, but it used to require <a href="http://stackoverflow.com/questions/127591/using-caps-lock-as-esc-in-mac-os-x#8437594">quite a bit of complexity</a>.</p>

<p>I recently moved to a new MacBook Pro with a Touch Bar and a virtual Esc key, so I decided to look into it again.</p>

<p>As of macOS Sierra 10.12.1, it’s incredibly simple.</p>

<ol>
  <li>Open System Preferences</li>
  <li>Go to the Keyboard pane and select the Keyboard tab</li>
  <li>Click the Modifier Keys… button on the bottom right</li>
  <li>From the popup menu to the right of “Caps Lock (⇪) Key”, select “⎋ Escape”</li>
</ol>

    
    ]]>
</description>
<pubDate>Wed, 12 Apr 2017 00:00:00 -0400</pubDate>
<link>http://localhost:4000/2017/04/12/caps-lock-to-escape.html</link>
<guid isPermaLink="true">http://localhost:4000/2017/04/12/caps-lock-to-escape.html</guid>
</item>

<item>
<title>Recent Reading: Disrupted and Blitzed</title>

<description>
    <![CDATA[
    

    
        


  <div class="clear-block"></div>
  <h3>Books</h3>
  <ul class="reading-list">
    
      <li>
        
    <span class="citation">
      
        <a href="http://www.amazon.com/exec/obidos/asin/0316306096/ref=nosim/latin031-20">Dan Lyons. <i>Disrupted: My Misadventure in the Start-Up Bubble</i>. New York: Hachette Books, 2016.</a>
      
    </span>

        
          <span class="note"><p>Dan Lyons’s memoir of his time as a conspicuously older employee in the twenty-something culture of HubSpot is a readable and entertaining evisceration of both the obvious and some of the more insidious poisonous aspects of Silicon Valley workplace culture. His experience as a tech journalist at <em>Newsweek</em> and elsewhere means that he also from time to time has some interesting insights into the strengths (and more often weaknesses) of HubSpot’s business which makes more edifying reading than a simple tour through a horror show.</p>
</span>
        
        
    <span class="links">
      
        <a href="http://worldcat.org/oclc/917344238">WorldCat &raquo;</a>
      
      
        <a href="http://www.amazon.com/exec/obidos/asin/0316306096/ref=nosim/latin031-20">Amazon &raquo;</a>
      
    </span>

      </li>
    
      <li>
        
    <span class="citation">
      
        <a href="http://www.amazon.com/exec/obidos/asin/1416507787/ref=nosim/latin031-20">Clifford Stoll. <i>The Cuckoo’s Egg: Tracking a Spy Through the Maze of Computer Espionage</i>. New York: Pocket Books, 2005.</a>
      
    </span>

        
          <span class="note"><p>I love post-mortem and process reading. <em>The Cuckoo’s Egg</em> is essentially a narrativization of Cliff Stoll’s logbook of a months-long surveillance of a hacker on his Berkeley computer lab’s Unix systems, and I found the sincere, guileless enthusiasm and detail with which he chronicled his work fascinating. From a historical perspective, the different level of infosec expectations at relatively sensitive sites on this early Internet compared versus basic consumer security expectations more than thirty years later is striking.</p>
</span>
        
        
    <span class="links">
      
        <a href="http://worldcat.org/oclc/804817769">WorldCat &raquo;</a>
      
      
        <a href="http://www.amazon.com/exec/obidos/asin/1416507787/ref=nosim/latin031-20">Amazon &raquo;</a>
      
    </span>

      </li>
    
      <li>
        
    <span class="citation">
      
        <a href="http://www.amazon.com/exec/obidos/asin/1937557383/ref=nosim/latin031-20">David Demaree. <i>Git for Humans</i>. New York: A Book Apart, 2016.</a>
      
    </span>

        
          <span class="note"><p>I use Git all day every day but, probably like most, only barely scratch the surface of its functionality. From a practical standpoint, Demaree’s book also does not go particularly deep into esoteric features of the software; I might have learned one or two practical tips and tricks. The book is instead a concise, accessible encapsulation of Git’s design perspective meant to help people engage with it on its own terms. As with many of the books in the <a href="https://abookapart.com/">A Book Apart</a> series, its strength comes in the tightness and directness of its purpose. It’s difficult to point to a single insight that I have not yet encountered elsewhere or stumbled upon on my own, but I nonetheless have a better sense of what to expect from Git from encountering all of these ideas together, organized in this way, and articulated this clearly and succinctly.</p>
</span>
        
        
    <span class="links">
      
        <a href="http://worldcat.org/oclc/946886836">WorldCat &raquo;</a>
      
      
        <a href="http://www.amazon.com/exec/obidos/asin/1937557383/ref=nosim/latin031-20">Amazon &raquo;</a>
      
    </span>

      </li>
    
      <li>
        
    <span class="citation">
      
        <a href="http://www.amazon.com/exec/obidos/asin/1328663795/ref=nosim/latin031-20">Norman Ohler. <i>Blitzed: Drugs in the Third Reich</i>. Translated by Shaun Whiteside. Boston: Houghton Mifflin Harcourt, 2017.</a>
      
    </span>

        
          <span class="note"><p>Having spent last year in Berlin (and returning this year for the summer), I’ve been getting back into reading twentieth century European for the first time in roughly twenty years. Having heard about <em>Blitzed</em> on the <a href="http://dobyfriday.com/19">Do By Friday</a> podcast, I thought it would introduce a lighter vein to that area of my reading. Ohler is not as historiographically disciplined as a writer trained as a historian might be, but his account is nonetheless at least very suggestive and is certainly entertaining and disturbing. Sometimes the account—particularly in its riffs on the relationship between Hitler and his private physician—may indulge a little too much in the salacious for my tastes, but Ohler’s central conceit that the story of Hitler’s dependency and perhaps addictions is essential for its subversion of Nazism’s claim to moral purity is convincing.</p>
</span>
        
        
    <span class="links">
      
        <a href="http://worldcat.org/oclc/965781501">WorldCat &raquo;</a>
      
      
        <a href="http://www.amazon.com/exec/obidos/asin/1328663795/ref=nosim/latin031-20">Amazon &raquo;</a>
      
    </span>

      </li>
    
  </ul>

    
    ]]>
</description>
<pubDate>Fri, 07 Apr 2017 16:30:01 -0400</pubDate>
<link>http://localhost:4000/2017/04/07/disrupted-and-blitzed.html</link>
<guid isPermaLink="true">http://localhost:4000/2017/04/07/disrupted-and-blitzed.html</guid>
</item>

<item>
<title>Ben Thompson on Specialized AI</title>

<description>
    <![CDATA[
    <blockquote>
  <p>What is kind of amusing — and telling — is that as John McCarthy, who invented the name “Artificial Intelligence”, <a href="http://cacm.acm.org/magazines/2012/1/144824-artificial-intelligence-past-and-future/fulltext">noted</a>, the definition of specialized AI is changing all of the time. Specifically, once a task formerly thought to characterize artificial intelligence becomes routine — like the aforementioned chess-playing, or Go, or a myriad of other taken-for-granted computer abilities — we no longer call it artificial intelligence.</p>

  <p>– <cite>Ben Thompson, <a href="https://stratechery.com/2017/the-arrival-of-artificial-intelligence/">The Arrival of Artificial Intelligence</a></cite></p>
</blockquote>

    
    ]]>
</description>
<pubDate>Wed, 29 Mar 2017 14:20:01 -0400</pubDate>
<link>http://localhost:4000/2017/03/29/thomspon-on-specialized-ai.html</link>
<guid isPermaLink="true">http://localhost:4000/2017/03/29/thomspon-on-specialized-ai.html</guid>
</item>

<item>
<title>Recent Reading: Alibaba, Vegetarian History, and 90’s Dystopia</title>

<description>
    <![CDATA[
    
    
        


  <div class="clear-block"></div>
  <h3>Books</h3>
  <ul class="reading-list">
    
      <li>
        
    <span class="citation">
      
        <a href="http://www.amazon.com/exec/obidos/asin/0062413406/ref=nosim/latin031-20">Duncan Clark. <i>Alibaba: The House that Jack Ma Built</i>. New York: Ecco, 2016.</a>
      
    </span>

        
          <span class="note"><p>Duncan Clark is a former analyst with Morgan Stanley, and his background is readily apparent for better and worse in his approach to this book. His personal experience in the early days of the Internet business in China, including with Alibaba itself, means he has keen insights into the formation of Alibaba that is frequently elided with cliché and comparisons to Amazon in other accounts. However, the granularity of detail and lack of synthesis can make the account drag from time-to-time, particularly in the middle to late stages.  I’m glad I’ve read this, but would also be interested in a more analytical account.</p>
</span>
        
        
    <span class="links">
      
        <a href="http://worldcat.org/oclc/952386514">WorldCat &raquo;</a>
      
      
        <a href="http://www.amazon.com/exec/obidos/asin/0062413406/ref=nosim/latin031-20">Amazon &raquo;</a>
      
    </span>

      </li>
    
      <li>
        
    <span class="citation">
      
        <a href="http://www.amazon.com/exec/obidos/asin/1250006252/ref=nosim/latin031-20">The Moosewood Collective and Jim Scherer. <i>Moosewood Restaurant Favorites: The 250 Most-Requested Naturally Delicious Recipes from One of America’s Best-Loved Restaurants</i>. New York: St. Martin’s Griffin, 2013.</a>
      
    </span>

        
          <span class="note"><p>The organizing principal of this Moosewood cookbook was to collect the recipes that for which employees hear the most requests from patrons which makes it a good single stop for those not ready to work through the dozen or so other books they’ve put out. Published in 2013, it is a fortieth anniversary commemoration of sorts for the restaurant and includes some nice front-matter on the history of the restaurant, its role in promoting vegetarian diets and healthful eating, and how the food industry has changed in the United States in the last 40 years.</p>
</span>
        
        
    <span class="links">
      
        <a href="http://worldcat.org/oclc/886578768">WorldCat &raquo;</a>
      
      
        <a href="http://www.amazon.com/exec/obidos/asin/1250006252/ref=nosim/latin031-20">Amazon &raquo;</a>
      
    </span>

      </li>
    
      <li>
        
    <span class="citation">
      
        <a href="http://www.amazon.com/exec/obidos/asin/0553566067/ref=nosim/latin031-20">William Gibson. <i>Virtual Light</i>. New York: Bantam Books, 1993.</a>
      
    </span>

        
          <span class="note"><p>This one from Gibson strikes me as all setting and world-building around a pretty tight, but shallow, thriller plot. There is only limited exploration of the sociological and technological consequences of the world he builds relative to some of his other work, but lots of interesting bits to pick out of the setting nonetheless.</p>
</span>
        
        
    <span class="links">
      
        <a href="http://worldcat.org/oclc/271481154">WorldCat &raquo;</a>
      
      
        <a href="http://www.amazon.com/exec/obidos/asin/0553566067/ref=nosim/latin031-20">Amazon &raquo;</a>
      
    </span>

      </li>
    
  </ul>

    
    ]]>
</description>
<pubDate>Tue, 14 Mar 2017 15:13:00 -0400</pubDate>
<link>http://localhost:4000/2017/03/14/moosewood-alibaba-virtual-light.html</link>
<guid isPermaLink="true">http://localhost:4000/2017/03/14/moosewood-alibaba-virtual-light.html</guid>
</item>

<item>
<title>Jeremy Adelman on Global History</title>

<description>
    <![CDATA[
    <blockquote>
  <p>Going deeper into the stories of Others afar and Strangers at home means dispensing with the idea that global integration was like an electric circuit, bringing light to the connected. Becoming inter-dependent is not just messier than drawing a wiring diagram. It means reckoning with dimensions of networks and circuits that global historians – and possibly all narratives of cosmopolitan convergence – leave out of the story: lighting up corners of the earth leaves others in the dark.  The story of the globalists illuminates some at the expense of others, the left behind, the ones who cannot move, and those who become immobilised because the light no longer shines on them.</p>

  <p>– <cite>Jeremy Adelman, <a href="https://aeon.co/essays/is-global-history-still-possible-or-has-it-had-its-moment">What is Global History Now?</a></cite></p>
</blockquote>

    
    ]]>
</description>
<pubDate>Fri, 03 Mar 2017 14:46:01 -0500</pubDate>
<link>http://localhost:4000/2017/03/03/adelman-on-global-history.html</link>
<guid isPermaLink="true">http://localhost:4000/2017/03/03/adelman-on-global-history.html</guid>
</item>

<item>
<title>Recent Reading: Futurists and Brotzeit</title>

<description>
    <![CDATA[
    

    
        


  <div class="clear-block"></div>
  <h3>Books</h3>
  <ul class="reading-list">
    
      <li>
        
    <span class="citation">
      
        <a href="http://www.amazon.com/exec/obidos/asin/0374534977/ref=nosim/latin031-20">Warren Ellis. <i>Normal</i>. New York: Farrar, Straus and Giroux, 2016.</a>
      
    </span>

        
          <span class="note"><p>I discovered today that, mostly by accident, I have read Warren Ellis more than any other author since I started making these posts a couple of years ago. <em>Normal</em> provides more of what I’ve been enjoying from him: sardonic humor, compact writing, and interesting critique—in this case of surveillance culture, futurism, and technological solutionism. Originally published as an e-book serial, I read it in print in a single volume. I might have preferred to read it serially; the disjointed, episodic rhythm accentuated the unstable setting.</p>
</span>
        
        
    <span class="links">
      
        <a href="http://worldcat.org/oclc/952277013">WorldCat &raquo;</a>
      
      
        <a href="http://www.amazon.com/exec/obidos/asin/0374534977/ref=nosim/latin031-20">Amazon &raquo;</a>
      
    </span>

      </li>
    
      <li>
        
    <span class="citation">
      
        <a href="http://www.amazon.com/exec/obidos/asin/1452128065/ref=nosim/latin031-20">Jeremy Nolen and Jessica Nolen. <i>New German Cooking: Recipes for Classics Revisited</i>. San Francisco, CA: Chronicle Books, 2015.</a>
      
    </span>

        
          <span class="note"><p>This book does a great job of introducing some nice, light-handed twists on German classics. While we were living in Berlin a lot of my favorite stuff were the vegetable dishes we don’t see a lot of in the States, and one of the Nolens’ hobby horses is that Americans stop associating the German kitchen only with sausage and beer. Not everything in the book is the friendliest for home-cooks (the pickling and charcuterie recipes, for example, tend to be for fairly large quantities), but the book is lovely nonetheless. The authors are the executive and pastry chefs at Brauhaus Schmitz in Philadelphia which I now am excited to try on our next visit.</p>
</span>
        
        
    <span class="links">
      
        <a href="http://worldcat.org/oclc/910968956">WorldCat &raquo;</a>
      
      
        <a href="http://www.amazon.com/exec/obidos/asin/1452128065/ref=nosim/latin031-20">Amazon &raquo;</a>
      
    </span>

      </li>
    
  </ul>

    
    ]]>
</description>
<pubDate>Mon, 27 Feb 2017 20:21:03 -0500</pubDate>
<link>http://localhost:4000/2017/02/27/recent-reading.html</link>
<guid isPermaLink="true">http://localhost:4000/2017/02/27/recent-reading.html</guid>
</item>

<item>
<title>Screenscraping Wikipedia with Python</title>

<description>
    <![CDATA[
    <p>Yesterday I did a very quick screen-scraping and text-manipulation project with a Wikipedia page that I thought I would write up as an example of using scripting for small ephemeral or one-off tasks. I used Python 3 with the <a href="http://docs.python-requests.org/en/master/">Requests</a> and <a href="https://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a>.</p>

<p>I recently had occasion to compile a corpus of river names for use as throwaway names for an in-house project. I’ve also been thinking a lot about lists and how they can be used and their makers over the last year and have tried (mostly unsuccessfully) to get in the habit of capturing ephemeral lists of things to this site.</p>

<p>While collecting my river names from Wikipedia, I came across a nice, well-encapsulated list of the longest rivers in Europe, so I thought I’d <a href="http://tinaja.computer/2017/02/17/longest-european-rivers.html">grab it</a> for one of these infrequent list posts.</p>

<hr />

<p>First, I import the two libraries I need. Requests will just make grabbing the Wikipedia page super-easy. BeautifulSoup will help me drill through the HTML I pull from Wikipedia to isolate just the pieces of the page that I’m interested in.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">requests</span>
</code></pre>
</div>

<p>The list I wanted to isolate was on the <a href="https://en.wikipedia.org/wiki/List_of_rivers_of_Europe">List of rivers of Europe</a> page on Wikipedia. It’s for rivers with a length longer than 250km, and it’s displayed in a separate 4 column table with a header row at the top. The first column of each row following the header has a name of the river with a link to its page on Wikipedia. I want to take all of those names and URLs and output them as a Markdown-formatted list of links. I’m not interested in the contents of any of the other columns.</p>

<p>First, I needed to do a little bit of poking around to find where in the page this table fell and what its markup looked like. I could have done this with the DOM inspector in a web browser, but instead I decided to just start from code. I knew it was in a table, so I first just grabbed the contents of the web page, asked BeautifulSoup to give me only the table elements in the page, and printed each of them out.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'https://en.wikipedia.org/wiki/List_of_rivers_of_Europe'</span><span class="p">)</span>

<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s">'html.parser'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">table</span> <span class="ow">in</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'table'</span><span class="p">):</span>
  <span class="k">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
</code></pre>
</div>

<p>Scrolling through my output, I verify that the table I’m interested in is the second table on the page. I don’t care about being able to reuse this code again later, so I it’s fine with me just to hardcode this value in.</p>

<p>Also looking at the output, I confirm that I’m not interested in the first row of the table (it’s just header information), and that the markup of the interesting rows is very straightforward:</p>

<div class="language-html highlighter-rouge"><pre class="highlight"><code><span class="nt">&lt;tr&gt;</span>
<span class="nt">&lt;td&gt;&lt;a</span> <span class="na">href=</span><span class="s">"/wiki/Volga_River"</span> <span class="na">title=</span><span class="s">"Volga River"</span><span class="nt">&gt;</span>Volga<span class="nt">&lt;/a&gt;&lt;/td&gt;</span>
<span class="nt">&lt;td&gt;</span>3,692<span class="nt">&lt;/td&gt;</span>
<span class="nt">&lt;td&gt;</span>2,294<span class="nt">&lt;/td&gt;</span>
<span class="nt">&lt;td&gt;&lt;a</span> <span class="na">href=</span><span class="s">"/wiki/Caspian_Sea"</span> <span class="na">title=</span><span class="s">"Caspian Sea"</span><span class="nt">&gt;</span>Caspian Sea<span class="nt">&lt;/a&gt;&lt;sup</span> <span class="na">class=</span><span class="s">"reference"</span> <span class="na">id=</span><span class="s">"cite_ref-1"</span><span class="nt">&gt;&lt;a</span> <span class="na">href=</span><span class="s">"#cite_note-1"</span><span class="nt">&gt;</span>[1]<span class="nt">&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;</span>
<span class="nt">&lt;/tr&gt;</span>
</code></pre>
</div>

<p>From this code, I can see that I’m interested in the first <code class="highlighter-rouge">td</code> cell of each row of the table, and I want the URL in the <code class="highlighter-rouge">href</code> attribute and the text contents of the link in that cell. As a run through the rows of the table, I will take these two elements and combine them as a Markdown-formatted link and append this link as a new list item to a string that will be output at the end of the script.</p>

<hr />

<p>So, to build the final script, I do my imports, grab the text I’m working with, and set up the HTML parser and the variable to start my final output.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'https://en.wikipedia.org/wiki/List_of_rivers_of_Europe'</span><span class="p">)</span>

<span class="c"># Give the text of the Wikipedia page to BeautifulSoup and have it</span>
<span class="c"># parse the HTML into a structured object</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s">'html.parser'</span><span class="p">)</span>

<span class="c"># I will append a new line for each river to this variable and </span>
<span class="c"># output all at once at the end</span>
<span class="n">output</span> <span class="o">=</span> <span class="s">""</span>
</code></pre>
</div>

<p>I then grab the second table in the page, get a handle for the first row from that table, and use that handle to get a handle to the following row using <code class="highlighter-rouge">find_next_sibling()</code>. This will be the second row in the table—the first row of data I’m interested in.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># The Longest Rivers list is the second table on the page</span>
<span class="n">long_rivers_table</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'table'</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">first_row</span> <span class="o">=</span> <span class="n">long_rivers_table</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'tr'</span><span class="p">)</span>

<span class="c"># Skip the first row of the table…</span>
<span class="n">row</span> <span class="o">=</span> <span class="n">first_row</span><span class="o">.</span><span class="n">find_next_sibling</span><span class="p">()</span>
</code></pre>
</div>

<p>I will use a <code class="highlighter-rouge">while</code> loop to step through the remaining rows of the table. While my <code class="highlighter-rouge">row</code> variable is not <code class="highlighter-rouge">None</code>, I’ll look for the first link in the first cell of the row and grab the information I’m interested in.</p>

<p>After I’ve output that information in my desired format, I set my <code class="highlighter-rouge">row</code> variable to its next sibling. If it has one, the loop will continue. If it does not, <code class="highlighter-rouge">row</code> will be <code class="highlighter-rouge">None</code> and my loop will end.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># …and step through the remaining rows</span>
<span class="k">while</span> <span class="n">row</span><span class="p">:</span>
    <span class="n">first_cell</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'td'</span><span class="p">)</span>
    <span class="n">link</span> <span class="o">=</span> <span class="n">first_cell</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'a'</span><span class="p">)</span>
    
    <span class="c"># Wikipedia uses relative URLs so I need to put the right</span>
    <span class="c"># stem on them for them to work as absolute URLs.</span>
    <span class="n">href</span> <span class="o">=</span> <span class="s">"https://en.wikipedia.org{}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">link</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'href'</span><span class="p">))</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">link</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>
  
    <span class="c"># Append a new line to my output with a new list item formatted</span>
    <span class="c"># as a Markdown link</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">+</span> <span class="s">"- [{}]({})</span><span class="se">\n</span><span class="s">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">href</span><span class="p">)</span>
    
    <span class="n">row</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">find_next_sibling</span><span class="p">()</span>
</code></pre>
</div>

<p>At the end of this loop, I now have a string of Markdown-formatted text of my list of rivers as a unordered list of links stored in <code class="highlighter-rouge">output</code>. I just print that to the screen to be copy-and-pasted where I like, and I’m done.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</code></pre>
</div>

<hr />

<p>There was a problem with this approach, however. I wasn’t looking carefully when I first defined my problem, and there are actually a few cells in this table where the contents are not simply a single link. There are few rows that list multiple rivers together in orographic order with separate links; there are also a few rows that list a plain text alternative name for the primary name of the river contained in the link.</p>

<p>So this section of my code from above was a bit too naïve:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>  <span class="n">link</span> <span class="o">=</span> <span class="n">first_cell</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'a'</span><span class="p">)</span>
    
  <span class="c"># Wikipedia uses relative URLs so I need to put the right</span>
    <span class="c"># stem on them for them to work as absolute URLs.</span>
    <span class="n">href</span> <span class="o">=</span> <span class="s">"https://en.wikipedia.org{}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">link</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'href'</span><span class="p">))</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">link</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>
  
    <span class="c"># Append a new line to my output with a new list item formatted</span>
    <span class="c"># as a Markdown link</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">+</span> <span class="s">"- [{}]({})</span><span class="se">\n</span><span class="s">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">href</span><span class="p">)</span>
</code></pre>
</div>

<p>I still want Markdown-formatted output, so I can’t just copy over the contents of the cell directly.</p>

<p>BeautifulSoup gives me what I need here. I can use the <code class="highlighter-rouge">contents</code> property of the first cell of the table. It is a list of the nodes contained in that cell, which in this case will be 1-n elements that are either links or plain text.</p>

<p>So now for each step through my loop, I will have an intermediate output variable <code class="highlighter-rouge">row_output</code> to use in constructing the output just for that individual row. As I step through the contents of that row, I will do one of two things depending on whether I’m dealing with plain text or a link. If I have plain text, I will copy it directly over to the output variable. If I a link, I will generate a Markdown-formatted version of that link and append it to the intermediate variable. Finally I will append a new list item to my <code class="highlighter-rouge">output</code> variable based on the contents of this intermediate variable and check whether I have another row to look at as before.</p>

<p>Now each run through my loop looks like this:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">row_output</span> <span class="o">=</span> <span class="s">""</span> <span class="c"># Reset row_output</span>
    
<span class="n">first_cell</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'td'</span><span class="p">)</span>
    
<span class="c"># Step through the contents of the first cell</span>
<span class="k">for</span> <span class="n">el</span> <span class="ow">in</span> <span class="n">first_cell</span><span class="o">.</span><span class="n">contents</span><span class="p">:</span>
    <span class="c"># Check to see whether this element of the list is a string instance</span>
    <span class="c"># in order to determine whether we’re dealing with plain text or a link</span>
    
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">el</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span> <span class="c"># This node of the document is just plain text</span>
        <span class="c"># Append the text directly to row_output</span>
        <span class="n">row_output</span> <span class="o">=</span> <span class="n">row_output</span> <span class="o">+</span> <span class="n">el</span>
        
    <span class="k">else</span><span class="p">:</span> <span class="c"># This node of the document is a link</span>
        <span class="c"># Wikipedia uses relative URLs so I need to put the right</span>
        <span class="c"># stem on them for them to work as absolute URLs.</span>
        <span class="n">href</span> <span class="o">=</span> <span class="s">"https://en.wikipedia.org{}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">el</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'href'</span><span class="p">))</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">el</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>

        <span class="c"># Append a Markdown-formatted link to row_output</span>
        <span class="n">row_output</span> <span class="o">=</span> <span class="n">row_output</span> <span class="o">+</span> <span class="s">"[{}]({})"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">href</span><span class="p">)</span>

<span class="c"># Append the compiled output for this row to the final output for the script</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">+</span> <span class="s">"- {}</span><span class="se">\n</span><span class="s">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">row_output</span><span class="p">)</span>
</code></pre>
</div>

<p>It’s a little more complicated, but much more robust in handling the few unusual elements in the list. This list wasn’t necessarily long enough that I absolutely needed to automate handling this small handful of exceptions, but with a larger corpus it would have been helpful and at least this way I know I won’t miss any while editing manually.</p>

<p>The complete source for the script follows (and is available as a <a href="https://gist.github.com/jonesbp/f9ffa3ec93bb8c8ec655a7403ea96b66">gist</a>).</p>

<hr />

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'https://en.wikipedia.org/wiki/List_of_rivers_of_Europe'</span><span class="p">)</span>

<span class="c"># Give the text of the Wikipedia page to BeautifulSoup and have it</span>
<span class="c"># parse the HTML into a structured object</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s">'html.parser'</span><span class="p">)</span>

<span class="c"># I will append a new line for each river to this variable and </span>
<span class="c"># output all at once at the end</span>
<span class="n">output</span> <span class="o">=</span> <span class="s">""</span>

<span class="c"># The Longest Rivers list is the second table on the page</span>
<span class="n">long_rivers_table</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'table'</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">first_row</span> <span class="o">=</span> <span class="n">long_rivers_table</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'tr'</span><span class="p">)</span>

<span class="c"># Skip the first row of the table…</span>
<span class="n">row</span> <span class="o">=</span> <span class="n">first_row</span><span class="o">.</span><span class="n">find_next_sibling</span><span class="p">()</span>

<span class="c"># …and step through the remaining rows</span>
<span class="k">while</span> <span class="n">row</span><span class="p">:</span>
    <span class="n">row_output</span> <span class="o">=</span> <span class="s">""</span> <span class="c"># Reset row_output</span>
    
    <span class="n">first_cell</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'td'</span><span class="p">)</span>
    
    <span class="c"># Step through the contents of the first cell</span>
    <span class="k">for</span> <span class="n">el</span> <span class="ow">in</span> <span class="n">first_cell</span><span class="o">.</span><span class="n">contents</span><span class="p">:</span>
        <span class="c"># Check to see whether this element of the list is a string instance</span>
        <span class="c"># in order to determine whether we’re dealing with plain text or a link</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">el</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span> <span class="c"># This node of the document is just plain text</span>
            <span class="c"># Append the text directly to row_output</span>
            <span class="n">row_output</span> <span class="o">=</span> <span class="n">row_output</span> <span class="o">+</span> <span class="n">el</span>
            
        <span class="k">else</span><span class="p">:</span> <span class="c"># This node of the document is a link</span>
            <span class="c"># Wikipedia uses relative URLs so I need to put the right</span>
            <span class="c"># stem on them for them to work as absolute URLs.</span>
            <span class="n">href</span> <span class="o">=</span> <span class="s">"https://en.wikipedia.org{}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">el</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'href'</span><span class="p">))</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">el</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>
            
            <span class="c"># Append a Markdown-formatted link to row_output</span>
            <span class="n">row_output</span> <span class="o">=</span> <span class="n">row_output</span> <span class="o">+</span> <span class="s">"[{}]({})"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">href</span><span class="p">)</span>
        
    <span class="c"># Append the compiled output for this row to the final output for the script</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">+</span> <span class="s">"- {}</span><span class="se">\n</span><span class="s">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">row_output</span><span class="p">)</span>
    
    <span class="c"># Get the next row if it exists</span>
    <span class="n">row</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">find_next_sibling</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</code></pre>
</div>


    
    ]]>
</description>
<pubDate>Sat, 18 Feb 2017 00:00:00 -0500</pubDate>
<link>http://localhost:4000/2017/02/18/screenscraping-wikipedia.html</link>
<guid isPermaLink="true">http://localhost:4000/2017/02/18/screenscraping-wikipedia.html</guid>
</item>

<item>
<title>Longest Rivers in Europe</title>

<description>
    <![CDATA[
    <p>Playing with list-making and naming bodies of water recently for a couple projects.</p>

<p>These are the rivers in Europe longer than 250km, sorted in descending length.</p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Volga_River">Volga</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Danube">Danube</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Ural_River">Ural</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Dnieper_River">Dnieper</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Don_River_(Russia)">Don</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Pechora_River">Pechora</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Kama_River">Kama</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Northern_Dvina_River">Northern Dvina</a>–<a href="https://en.wikipedia.org/wiki/Vychegda_River">Vychegda</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Oka_River">Oka</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Belaya_River_(Kama)">Belaya</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Dniester">Dniester</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Rhine">Rhine</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Elbe">Elbe</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Donets_River">Donets</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Vistula_River">Vistula</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Tagus">Tagus</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Daugava_River">Daugava</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Loire_(river)">Loire</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Tisza">Tisza</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Prut_River">Prut</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Sava">Sava</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Neman_River">Neman</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Meuse_(river)">Meuse</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Ebro">Ebro</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Douro">Douro</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Kuban_River">Kuban</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Mezen_River">Mezen</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Oder">Oder</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Rh%C3%B4ne">Rhône</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Warta">Warta</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Mure%C8%99_River">Mureș</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Seine">Seine</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Bug_River">Bug</a></li>
  <li><a href="https://en.wikipedia.org/wiki/G%C3%B6ta_%C3%A4lv">Göta älv</a>-<a href="https://en.wikipedia.org/wiki/Klar%C3%A4lven">Klarälven</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Drava">Drava</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Guadiana">Guadiana</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Siret_River">Siret</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Po_(river)">Po</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Guadalquivir">Guadalquivir</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Glomma">Glomma</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Olt_River">Olt</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Garonne">Garonne</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Neva_River">Neva</a>–<a href="https://en.wikipedia.org/wiki/Svir_River">Svir</a>–<a href="https://en.wikipedia.org/wiki/Suna_River">Suna</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Kemijoki">Kemijoki</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Moselle_(river)">Moselle</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Dal_River">Dal River</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Torne">Torne</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Neris">Neris</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Narew">Narew</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Maritsa">Maritsa</a>/Evros</li>
  <li><a href="https://en.wikipedia.org/wiki/Mur_(river)">Mur</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Ume_River">Ume River</a></li>
  <li><a href="https://en.wikipedia.org/wiki/%C3%85ngerman_River">Ångerman River</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Lule_River">Lule River</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Kalix_River">Kalix River</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Vindel_River">Vindel River</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Gauja">Gauja</a></li>
  <li><a href="https://en.wikipedia.org/wiki/San_(river)">San</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Ljusnan">Ljusnan</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Skellefte_River">Skellefte River</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Indal_River">Indal River</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Vltava">Vltava</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Ialomi%C8%9Ba_River">Ialomița</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Struma_(river)">Struma</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Adige">Adige</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Tiber">Tiber</a></li>
  <li><a href="https://en.wikipedia.org/wiki/V%C3%A1h">Váh</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Pite_River">Pite River</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Fax%C3%A4lven">Faxälven</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Ljungan">Ljungan</a></li>
  <li><a href="https://en.wikipedia.org/wiki/R%C3%A1ba">Rába</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Vardar">Vardar</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Some%C8%99_River">Someș</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Paatsjoki">Paatsjoki</a>–<a href="https://en.wikipedia.org/wiki/Ivalo_(river)">Ivalojoki</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Muonionjoki">Muonionjoki</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Iijoki">Iijoki</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Iskar_(river)">Iskar</a></li>
  <li><a href="https://en.wikipedia.org/wiki/River_Shannon">River Shannon</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Numedalsl%C3%A5gen">Numedalslågen</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Vorma">Vorma</a>–<a href="https://en.wikipedia.org/wiki/Gudbrandsdalsl%C3%A5gen">Gudbrandsdalslågen</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Morava_(river)">Morava</a></li>
  <li><a href="https://en.wikipedia.org/wiki/River_Severn">River Severn</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Arge%C8%99_River">Argeș</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Tundzha">Tundzha</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Tana_(Norway)">Tana</a>–<a href="https://en.wikipedia.org/wiki/Anarjohka">Anarjohka</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Thames">Thames</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Drina">Drina</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Venta">Venta</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Minho">Minho</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Jiu_River">Jiu</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Timi%C8%99_River">Timiș</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Drin_(river)">Drin</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Haliacmon">Haliacmon</a></li>
  <li><a href="https://en.wikipedia.org/wiki/V%C3%A4sterdal_River">Västerdal River</a></li>
  <li><a href="https://en.wikipedia.org/wiki/West_Morava">West Morava</a>/(Zapadna Morava)</li>
  <li><a href="https://en.wikipedia.org/wiki/Drammenselva">Drammenselva</a>–<a href="https://en.wikipedia.org/wiki/Begna_(river)">Begna</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Norrstr%C3%B6m">Norrström</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Buz%C4%83u_River">Buzău</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Ounasjoki">Ounasjoki</a></li>
  <li><a href="https://en.wikipedia.org/wiki/%C5%A0e%C5%A1up%C4%97">Šešupė</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Kupa">Kupa</a></li>
  <li><a href="https://en.wikipedia.org/wiki/South_Morava">South Morava</a>/(Južna Morava)</li>
  <li><a href="https://en.wikipedia.org/wiki/D%C3%A2mbovi%C8%9Ba_River">Dâmbovița</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Yantra_(river)">Yantra</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Motala_str%C3%B6m">Motala ström</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Bistri%C8%9Ba_River_(Siret)">Bistrița</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Jijia_River_(Prut)">Jijia</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Vjos%C3%AB">Vjosë</a>/Aoos</li>
  <li><a href="https://en.wikipedia.org/wiki/River_Bosna">Bosna</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Skiensvassdraget">Skiensvassdraget</a></li>
  <li><a href="https://en.wikipedia.org/w/index.php?title=Fj%C3%A4llsj%C3%B6%C3%A4lven&amp;action=edit&amp;redlink=1">Fjällsjöälven</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Lainio_River">Lainio River</a></li>
  <li><a href="https://en.wikipedia.org/w/index.php?title=Snarumselva&amp;action=edit&amp;redlink=1">Snarumselva</a>–<a href="https://en.wikipedia.org/wiki/Hallingdalselva">Hallingdalselva</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Bega_River,_Romania_and_Serbia">Bega</a></li>
</ul>

<p><em><strong>Source:</strong> <a href="https://en.wikipedia.org/wiki/List_of_rivers_of_Europe">Wikipedia</a></em></p>

    
    ]]>
</description>
<pubDate>Fri, 17 Feb 2017 00:00:00 -0500</pubDate>
<link>http://localhost:4000/2017/02/17/longest-european-rivers.html</link>
<guid isPermaLink="true">http://localhost:4000/2017/02/17/longest-european-rivers.html</guid>
</item>

<item>
<title>Recent Reading: Cyberpunk and Sea Slugs</title>

<description>
    <![CDATA[
    <h3 id="links">Links</h3>

<ul>
  <li><a href="https://aeon.co/essays/theres-more-maths-in-slugs-and-corals-than-we-can-think-of"><strong>How to Play Mathematics—Aeon—Margaret Wertheim</strong></a>: Wertheim takes the hyperbolic geometry of sea slugs as a point of departure for a fascinating exploration of the experiential, tangible, and whimsical possibilities of mathematics.</li>
</ul>


    
        


  <div class="clear-block"></div>
  <h3>Books</h3>
  <ul class="reading-list">
    
      <li>
        
    <span class="citation">
      
        <a href="http://www.amazon.com/exec/obidos/asin/1400076099/ref=nosim/latin031-20">P.D. James. <i>The Murder Room</i>. New York: A.A. Knopf, 2003.</a>
      
    </span>

        
          <span class="note"><p>This is the first of the Adam Dalgliesh mysteries I’ve ever read, and I intend to read more. All of the comfortable and satisfying elements of a mystery novel are there, but James is a better writer and a keener social observer than most.</p>
</span>
        
        
    <span class="links">
      
        <a href="http://worldcat.org/oclc/53070196">WorldCat &raquo;</a>
      
      
        <a href="http://www.amazon.com/exec/obidos/asin/1400076099/ref=nosim/latin031-20">Amazon &raquo;</a>
      
    </span>

      </li>
    
      <li>
        
    <span class="citation">
      
        <a href="http://www.amazon.com/exec/obidos/asin/B01L9W8AHC/ref=nosim/latin031-20">Leigh Alexander. <i>Monitor</i>. Roseville, MN: Fantasy Flight, Games, 2016.</a>
      
    </span>

        
          <span class="note"><p>Alexander’s novella is set in the cyberpunk universe of the Android: Netrunner collectible card game. Alexander is a good writer and has done interesting work as a critic of games and online communities and experiences, so I found this experiment with a sort of ‘sanctioned fan fiction’ intriguing. I probably needed to know more about the card game to get more out of it from that perspective, but the story itself is a timely exploration of the overlapping modern media and surveillance environments.</p>
</span>
        
        
    <span class="links">
      
      
        <a href="http://www.amazon.com/exec/obidos/asin/B01L9W8AHC/ref=nosim/latin031-20">Amazon &raquo;</a>
      
    </span>

      </li>
    
      <li>
        
    <span class="citation">
      
        <a href="http://www.amazon.com/exec/obidos/asin/B01G9D1BOK/ref=nosim/latin031-20">Kate Leth, Brittney L. Williams, Natasha Allegri, and Megan Wilson. <i>Patsy Walker, a.k.a. Hellcat! Vol. 1, Hooked On a Feline</i>. New York: Marvel Enterprises, 2016.</a>
      
    </span>

        
          <span class="note"><p>Fun Marvel superhero stuff focusing on low-stakes, personal conflict with a great, bright color palette and light humorous voice.</p>
</span>
        
        
    <span class="links">
      
        <a href="http://worldcat.org/oclc/928614317">WorldCat &raquo;</a>
      
      
        <a href="http://www.amazon.com/exec/obidos/asin/B01G9D1BOK/ref=nosim/latin031-20">Amazon &raquo;</a>
      
    </span>

      </li>
    
  </ul>

    
    ]]>
</description>
<pubDate>Fri, 10 Feb 2017 15:48:49 -0500</pubDate>
<link>http://localhost:4000/2017/02/10/recent-reading.html</link>
<guid isPermaLink="true">http://localhost:4000/2017/02/10/recent-reading.html</guid>
</item>

<item>
<title>Recent Reading: Texas Cooking and Corals in Paris</title>

<description>
    <![CDATA[
    
    
        


  <div class="clear-block"></div>
  <h3>Books</h3>
  <ul class="reading-list">
    
      <li>
        
    <span class="citation">
      
        <a href="http://www.amazon.com/exec/obidos/asin/0451228731/ref=nosim/latin031-20">Daniel Suarez. <i>Daemon</i>. New York: Dutton, 2009.</a>
      
    </span>

        
          <span class="note"><p><em>Daemon</em> received a lot of attention about ten years ago from tech industry folks and computer programmers as a sort of “hard” techno-thriller in which computer technology served the plot according to an internal logic and with respect for actual computational and networking limitations in ways that fiction, film, and television so frequently get laughably wrong. The plot centers on a genius computer programmer and game development CEO with libertarian delusions of grandeur. The current political discussion around Silicon Valley arrogance made for an interesting juxtaposition for reading this novel a decade on from its initial publication.</p>
</span>
        
        
    <span class="links">
      
        <a href="http://worldcat.org/oclc/233548994">WorldCat &raquo;</a>
      
      
        <a href="http://www.amazon.com/exec/obidos/asin/0451228731/ref=nosim/latin031-20">Amazon &raquo;</a>
      
    </span>

      </li>
    
      <li>
        
    <span class="citation">
      
        <a href="http://www.amazon.com/exec/obidos/asin/0848745809/ref=nosim/latin031-20">Jessica Dupuy. <i>United Tastes of Texas: Authentic Recipes from All Corners of the Lone Star State</i>. New York: Oxmoor House, 2016.</a>
      
    </span>

        
          <span class="note"><p>This cookbook does a solid job of collecting the various regional influences of Texas cooking including the Southern-inspired food of East Texas, German and Czech influence in Central Texas, the seafood of the Gulf Coast, and the Tex-Mex of South Texas. There’s a good balance between more opinionated recipes adapted from individual chefs and interpretations of classic home-cooking recipes. Not every take on a traditional classic is my favorite example of that dish, but everything here is good and conveniences for home cooks have been taken into account without ruining the important parts.</p>
</span>
        
        
    <span class="links">
      
        <a href="http://worldcat.org/oclc/911070339">WorldCat &raquo;</a>
      
      
        <a href="http://www.amazon.com/exec/obidos/asin/0848745809/ref=nosim/latin031-20">Amazon &raquo;</a>
      
    </span>

      </li>
    
      <li>
        
    <span class="citation">
      
        <a href="http://www.amazon.com/exec/obidos/asin/0385531486/ref=nosim/latin031-20">Rebecca Stott. <i>The Coral Thief</i>. New York: Spiegel & Grau, 2009.</a>
      
    </span>

        
          <span class="note"><p><em>The Coral Thief</em> evokes the time and place of early nineteenth-century Paris wonderfully and is clearly the result of engaged research into the history of the era’s natural historians, naturalists, and their rivalries. In all, it was an enjoyable read. However, the execution of the setting was sufficiently engaging that it threw into relief some of the deficiencies in characterization—the two main characters are almost entirely flat on the one hand and fantastically complicated to a fantastical and incredible degree on the other—and plotting—in a final heist requiring silence characters who have worked together for years carry on expository conversations relating their shared personal histories to one another. In a pulpier thriller, I would not have noticed. Having bought into this setting completely, however, the moments that stretched credulity felt all the more jarring.</p>
</span>
        
        
    <span class="links">
      
        <a href="http://worldcat.org/oclc/297147171">WorldCat &raquo;</a>
      
      
        <a href="http://www.amazon.com/exec/obidos/asin/0385531486/ref=nosim/latin031-20">Amazon &raquo;</a>
      
    </span>

      </li>
    
  </ul>

    
    ]]>
</description>
<pubDate>Fri, 16 Dec 2016 07:00:00 -0500</pubDate>
<link>http://localhost:4000/2016/12/16/recent-reading.html</link>
<guid isPermaLink="true">http://localhost:4000/2016/12/16/recent-reading.html</guid>
</item>

</channel>
</rss>